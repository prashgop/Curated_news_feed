{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(385, 4)\n",
      "(335, 4)\n"
     ]
    }
   ],
   "source": [
    "# Task : Build an AI curated news feed for customers which shows only the article which are relavent for stocks customers have invested\n",
    "# in. \n",
    "\n",
    "\n",
    "from xml.dom import minidom\n",
    "import urllib\n",
    "import pandas as pd\n",
    "\n",
    "#Load the URL\n",
    "def load(rssURL):\n",
    "  return minidom.parse(urllib.request.urlopen(rssURL))\n",
    "\n",
    "DEFAULT_NAMESPACES = \\\n",
    "  (None, # RSS 0.91, 0.92, 0.93, 0.94, 2.0\n",
    "  'http://purl.org/rss/1.0/', # RSS 1.0\n",
    "  'http://my.netscape.com/rdf/simple/0.9/' # RSS 0.90\n",
    "  )\n",
    "\n",
    "#Retrieve elements of rss by tag name\n",
    "def getElementsByTagName(node, tagName, possibleNamespaces=DEFAULT_NAMESPACES):\n",
    "  for namespace in possibleNamespaces:\n",
    "    children = node.getElementsByTagNameNS(namespace, tagName)\n",
    "    if len(children): return children\n",
    "  return []\n",
    "\n",
    "def first(node, tagName, possibleNamespaces=DEFAULT_NAMESPACES):\n",
    "  children = getElementsByTagName(node, tagName, possibleNamespaces)\n",
    "  return len(children) and children[0] or None\n",
    "\n",
    "def textOf(node):\n",
    "  return node and \"\".join([child.data for child in node.childNodes]) or \"\"\n",
    "\n",
    "#Revalent news sources. More sources can be included later\n",
    "rssURL1 = 'http://articlefeeds.nasdaq.com/nasdaq/symbols?symbol={}'\n",
    "rssURL2 = 'https://www.marketwatch.com/rss/newsfinder/AllMarketWatchNews/?p=word&pv={}&t={}&dist=sr_rss'\n",
    "rssSource = [rssURL1, rssURL2]\n",
    "#Stock symbols for companies in which user has invested stocks in. \n",
    "#Apple, Facebook, Amazon, Netflix, Tesala, Cisco, Google, Baidu, Alibaba and Tencent\n",
    "symbols = ['AAPL', 'FB', 'AMZN', 'NFLX', 'TSLA', 'CSCO', 'GOOGL', 'BIDU', 'BABA', 'TCEHY']\n",
    "\n",
    "\n",
    "newsFeedDF = pd.DataFrame(columns = ['symbol','Headline', 'NewsURL', 'Summary'])\n",
    "\n",
    "#Populate news feed from a veraity of RSS news feeds\n",
    "def populateNewsFeed(df):\n",
    "    index = 0\n",
    "    for symbol in symbols:\n",
    "        for rssURL in rssSource:\n",
    "            rssDocument = load(rssURL.format(symbol,symbol))\n",
    "            for item in getElementsByTagName(rssDocument, 'item'):\n",
    "                df.loc[index] = pd.Series({'symbol': symbol,\n",
    "                                           'Headline' : textOf(first(item, 'title')),\n",
    "                                           'NewsURL' : textOf(first(item, 'link')),\n",
    "                                           'Summary' : textOf(first(item, 'description'))})\n",
    "                index+=1\n",
    "populateNewsFeed(newsFeedDF)\n",
    "\n",
    "# Remove duplicate entries from the collected news feed. Each entry can be uniquely identified by URL. So we need to \n",
    "#filter on URL and remove duplicate row entries\n",
    "\n",
    "print(newsFeedDF.shape)\n",
    "newsFeedDF.drop_duplicates(subset = ['NewsURL'], inplace=True)\n",
    "print(newsFeedDF.shape)\n",
    "\n",
    "#Relavent info is collected and now our feed uniquely identifies the symbol, URL, Summary and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to find sentiment of each news article and come up with a score to decide whether the news is positive or negetive.\n",
    "# For this purpose, approach taken is to find dictionaries containing positive and negetive words and then count \n",
    "# how many of each occur respectively in each article. \n",
    "# Used Sentiment Analysis of Financial Texts dictionary developed by  Prof Bill McDonald, \n",
    "#professor of Finance at the University of Notre Dame to identify the contextual meaning of financial text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the positive dictionary\n",
    "def loadPositive():\n",
    "    \"\"\"\n",
    "    loading positive dictionary\n",
    "    \"\"\"\n",
    "    myfile = open('LM_Positive.csv', \"r\")\n",
    "    positives = myfile.readlines()\n",
    "    positive = [pos.strip().lower() for pos in positives]\n",
    "    return positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load the negetive dictionary\n",
    "def loadNegative():\n",
    "    \"\"\"\n",
    "    loading negetive dictionary\n",
    "    \"\"\"\n",
    "    myfile = open('LM_Negative.csv', \"r\")\n",
    "    negatives = myfile.readlines()\n",
    "    negative = [neg.strip().lower() for neg in negatives]\n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Count negetive words in the text\n",
    "def countNeg(cleantext, negative):\n",
    "    \"\"\"\n",
    "    counts negative words in cleantext\n",
    "    \"\"\"\n",
    "    negs = [word for word in cleantext if word in negative]\n",
    "    return len(negs)\n",
    "\n",
    "#Count positive words in the text\n",
    "def countPos(cleantext, positive):\n",
    "    \"\"\"\n",
    "    counts negative words in cleantext\n",
    "    \"\"\"\n",
    "    pos = [word for word in cleantext if word in positive]\n",
    "    return len(pos)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the sentiment, by substracting no:of negetive words from no:of positive words\n",
    "def getSentiment(cleantext, negative, positive):\n",
    "    \"\"\"\n",
    "    counts negative and positive words in cleantext and returns a score accordingly\n",
    "    \"\"\"\n",
    "    positive = loadPositive()\n",
    "    negative = loadNegative()\n",
    "    return (countPos(cleantext, positive) - countNeg(cleantext, negative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Apply the sentiment generator on Summary text to come up with sentiment score\n",
    "def updateSentimentDataFrame(df):\n",
    "    \"\"\"\n",
    "    performs sentiment analysis on single text entry of dataframe and returns dataframe with scores\n",
    "    \"\"\"\n",
    "    positive = loadPositive()\n",
    "    negative = loadNegative()   \n",
    "    \n",
    "    df['text'] = df['Summary'].apply(cleanText)\n",
    "    df['Sentiment_score'] = df['text'].apply(lambda x: getSentiment(x,negative, positive))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk task to do text preprocessing\n",
    "def cleanText(text):\n",
    "    \"\"\"\n",
    "    removes punctuation, stopwords and returns lowercase text in a list of single words\n",
    "    \"\"\"\n",
    "    text = text.lower()    \n",
    "    \n",
    "    from nltk.tokenize import RegexpTokenizer\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    clean = [word for word in text if word not in stopwords.words('english')]\n",
    "    \n",
    "    return clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a sentiment score based on the summary text.\n",
    "#\n",
    "newsFeedDF = updateSentimentDataFrame(newsFeedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0    181\n",
      "-1     52\n",
      " 1     41\n",
      "-2     25\n",
      " 2     16\n",
      "-3      8\n",
      "-4      4\n",
      "-5      3\n",
      " 3      2\n",
      "-6      1\n",
      " 4      1\n",
      " 5      1\n",
      "Name: Sentiment_score, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(newsFeedDF['Sentiment_score'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsFeedDF = newsFeedDF.drop('text', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  symbol                                           Headline  \\\n",
      "0   AAPL  Validea&#39;s Top Five Technology Stocks Based...   \n",
      "1   AAPL  Big Technology&#39;s Spending Spree Is Great f...   \n",
      "2   AAPL                    Better Buy: Apple vs. Microsoft   \n",
      "3   AAPL  What Investors Need to Know About Intel&#39;s ...   \n",
      "4   AAPL  Warren Buffett Is Buying These 2 Stocks -- Sho...   \n",
      "\n",
      "                                             NewsURL  \\\n",
      "0  http://articlefeeds.nasdaq.com/~r/nasdaq/symbo...   \n",
      "1  http://articlefeeds.nasdaq.com/~r/nasdaq/symbo...   \n",
      "2  http://articlefeeds.nasdaq.com/~r/nasdaq/symbo...   \n",
      "3  http://articlefeeds.nasdaq.com/~r/nasdaq/symbo...   \n",
      "4  http://articlefeeds.nasdaq.com/~r/nasdaq/symbo...   \n",
      "\n",
      "                                             Summary  Sentiment_score  \n",
      "0  The following are the top rated Technology sto...                1  \n",
      "1  For many investors the tech bubble of the late...               -2  \n",
      "2  Technology kingpins Microsoft NASDAQ MSFT and ...                0  \n",
      "3  Computer chip giant Intel NASDAQ INTC has been...                0  \n",
      "4  We generally don t know what stocks Warren Buf...                0  \n"
     ]
    }
   ],
   "source": [
    "print(newsFeedDF.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
